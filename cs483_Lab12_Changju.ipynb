{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs483_Lab12_Changju.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs9RHkEi0xTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55099cd8-3985-4d1e-e07a-2159a20e1684"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=42)\n",
        "gbrt = GradientBoostingClassifier(learning_rate=0.01, random_state=0)\n",
        "\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "print('The decision function for the 3-class iris dataset:\\n\\n{}'.format(gbrt.decision_function(X_test[:10])))\n",
        "\n",
        "print('Predicted probabilities for the samples in the iris dataset:\\n\\n{}'.format(gbrt.predict_proba(X_test[:10])))\n",
        "\n",
        "#-------------Preprocessing-------\n",
        "\n",
        "from sklearn import preprocessing \n",
        "import numpy as np\n",
        "\n",
        "data = np.array([[2.2, 5.9, -1.8], [5.4, -3.2, -5.1], [-1.9, 4.2, 3.2]])\n",
        "bindata = preprocessing.Binarizer(threshold=1.5).transform(data) \n",
        "print('Binarized data:\\n\\n', bindata)\n",
        "\n",
        "print('Mean (before)= ', data.mean(axis=0)) \n",
        "print('Standard Deviation (before)= ', data.std(axis=0)) \n",
        "scaled_data = preprocessing.scale(data)\n",
        "\n",
        "print('Mean (after)= ', scaled_data.mean(axis=0)) \n",
        "print('Standard Deviation (after)= ', scaled_data.std(axis=0))\n",
        "\n",
        "data\n",
        "minmax_scaler = preprocessing.MinMaxScaler(feature_range=(0,1)) \n",
        "data_minmax = minmax_scaler.fit_transform(data) \n",
        "print('MinMaxScaler applied on the data:\\n', data_minmax)\n",
        "\n",
        "data\n",
        "data_l1 = preprocessing.normalize(data, norm='l1') \n",
        "data_l2 = preprocessing.normalize(data, norm='l2')\n",
        "\n",
        "print('L1-normalized data:\\n', data_l1) \n",
        "print('\\nL2-normalized data:\\n', data_l2)\n",
        "\n",
        "#--------------Label encoding---------------------\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/adult_data.txt', header=None, index_col=False, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
        "\n",
        "data = data[['age', 'workclass', 'education', 'gender', 'hours-per-week', 'occupation', 'income']]\n",
        "display(data)\n",
        "\n",
        "\n",
        "print('Original Features:\\n', list(data.columns), '\\n') \n",
        "data_dummies = pd.get_dummies(data)\n",
        "print('Features after One-Hot Encoding:\\n', list(data_dummies.columns))\n",
        "\n",
        "features = data_dummies.loc[:, 'age':'occupation_ Transport-moving']\n",
        "X = features.values\n",
        "y = data_dummies['income_ >50K'].values\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) \n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "print('Logistic Regression score on the test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
        "\n",
        "#-------------Automatic Feature Selection---------------\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.feature_selection import SelectPercentile \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "%matplotlib inline\n",
        "cancer = load_breast_cancer() \n",
        "rng = np.random.RandomState(42)\n",
        "noise = rng.normal(size=(len(cancer.data), 50))\n",
        "\n",
        "X_w_noise = np.hstack([cancer.data, noise])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_w_noise, cancer.target, random_state=0, test_size=.5)\n",
        "\n",
        "select = SelectPercentile(percentile=50) \n",
        "select.fit(X_train, y_train)\n",
        "X_train_selected = select.transform(X_train)\n",
        "\n",
        "print('X_train.shape is: {}'.format(X_train.shape)) \n",
        "print('X_train_selected.shape is: {}'.format(X_train_selected.shape))\n",
        "\n",
        "\n",
        "mask = select.get_support() \n",
        "print(mask)\n",
        "plt.matshow(mask.reshape(1,-1), cmap='gray_r')\n",
        "\n",
        "\n",
        "X_test_selected = select.transform(X_test) \n",
        "logreg = LogisticRegression() \n",
        "logreg.fit(X_train, y_train)\n",
        "print('The score of Logistic Regression on all features:{:.3f}'.format(logreg.score(X_test, y_test))) \n",
        "logreg.fit(X_train_selected, y_train)\n",
        "\n",
        "print('The score of Logistic Regression on the selected features:{:.3f}'.format(logreg.score(X_test_selected, y_test)))\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "select = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold='median')\n",
        "\n",
        "select.fit(X_train, y_train)\n",
        "X_train_s = select.transform(X_train) \n",
        "print('The shape of X_train is: ', X_train.shape)\n",
        "print('The shape of X_train_s is ', X_train_s.shape)\n",
        "\n",
        "mask = select.get_support() \n",
        "plt.matshow(mask.reshape(1,-1), cmap='gray_r') \n",
        "plt.xlabel('Index of Features')\n",
        "\n",
        "X_test_s = select.transform(X_test)\n",
        "score = LogisticRegression().fit(X_train_s, y_train).score(X_test_s, y_test) \n",
        "print('The score of Logistic Regression with the selected features on the test set:{:.3f}'.format(score))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "The decision function for the 3-class iris dataset:\n",
            "\n",
            "[[-1.9957153   0.04758118 -1.92721297]\n",
            " [ 0.0614655  -1.90755689 -1.92793177]\n",
            " [-1.99058105 -1.87637856  0.09686741]\n",
            " [-1.9957153   0.04758118 -1.92721297]\n",
            " [-1.99730166 -0.13469231 -1.20341532]\n",
            " [ 0.0614655  -1.90755689 -1.92793177]\n",
            " [-1.9957153   0.04758118 -1.92721297]\n",
            " [-1.9967734  -1.87637856  0.09686741]\n",
            " [-1.9957153   0.04758118 -1.92721297]\n",
            " [-1.9957153   0.04758118 -1.92721297]]\n",
            "Predicted probabilities for the samples in the iris dataset:\n",
            "\n",
            "[[0.10217734 0.78840063 0.10942203]\n",
            " [0.7834712  0.1093673  0.1071615 ]\n",
            " [0.09818079 0.11005862 0.79176059]\n",
            " [0.10217734 0.78840063 0.10942203]\n",
            " [0.10360014 0.66723882 0.22916105]\n",
            " [0.7834712  0.1093673  0.1071615 ]\n",
            " [0.10217734 0.78840063 0.10942203]\n",
            " [0.09763388 0.11012536 0.79224076]\n",
            " [0.10217734 0.78840063 0.10942203]\n",
            " [0.10217734 0.78840063 0.10942203]]\n",
            "Binarized data:\n",
            "\n",
            " [[1. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 1.]]\n",
            "Mean (before)=  [ 1.9         2.3        -1.23333333]\n",
            "Standard Deviation (before)=  [2.98775278 3.95052739 3.41207008]\n",
            "Mean (after)=  [0.00000000e+00 0.00000000e+00 7.40148683e-17]\n",
            "Standard Deviation (after)=  [1. 1. 1.]\n",
            "MinMaxScaler applied on the data:\n",
            " [[0.56164384 1.         0.39759036]\n",
            " [1.         0.         0.        ]\n",
            " [0.         0.81318681 1.        ]]\n",
            "L1-normalized data:\n",
            " [[ 0.22222222  0.5959596  -0.18181818]\n",
            " [ 0.39416058 -0.23357664 -0.37226277]\n",
            " [-0.20430108  0.4516129   0.34408602]]\n",
            "\n",
            "L2-normalized data:\n",
            " [[ 0.3359268   0.90089461 -0.2748492 ]\n",
            " [ 0.6676851  -0.39566524 -0.63059148]\n",
            " [-0.33858465  0.74845029  0.57024784]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>gender</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>occupation</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Male</td>\n",
              "      <td>13</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>11th</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Female</td>\n",
              "      <td>40</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32556</th>\n",
              "      <td>27</td>\n",
              "      <td>Private</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>Female</td>\n",
              "      <td>38</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32557</th>\n",
              "      <td>40</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32558</th>\n",
              "      <td>58</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Female</td>\n",
              "      <td>40</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32559</th>\n",
              "      <td>22</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Male</td>\n",
              "      <td>20</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32560</th>\n",
              "      <td>52</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Female</td>\n",
              "      <td>40</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32561 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age          workclass  ...          occupation  income\n",
              "0       39          State-gov  ...        Adm-clerical   <=50K\n",
              "1       50   Self-emp-not-inc  ...     Exec-managerial   <=50K\n",
              "2       38            Private  ...   Handlers-cleaners   <=50K\n",
              "3       53            Private  ...   Handlers-cleaners   <=50K\n",
              "4       28            Private  ...      Prof-specialty   <=50K\n",
              "...    ...                ...  ...                 ...     ...\n",
              "32556   27            Private  ...        Tech-support   <=50K\n",
              "32557   40            Private  ...   Machine-op-inspct    >50K\n",
              "32558   58            Private  ...        Adm-clerical   <=50K\n",
              "32559   22            Private  ...        Adm-clerical   <=50K\n",
              "32560   52       Self-emp-inc  ...     Exec-managerial    >50K\n",
              "\n",
              "[32561 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Original Features:\n",
            " ['age', 'workclass', 'education', 'gender', 'hours-per-week', 'occupation', 'income'] \n",
            "\n",
            "Features after One-Hot Encoding:\n",
            " ['age', 'hours-per-week', 'workclass_ ?', 'workclass_ Federal-gov', 'workclass_ Local-gov', 'workclass_ Never-worked', 'workclass_ Private', 'workclass_ Self-emp-inc', 'workclass_ Self-emp-not-inc', 'workclass_ State-gov', 'workclass_ Without-pay', 'education_ 10th', 'education_ 11th', 'education_ 12th', 'education_ 1st-4th', 'education_ 5th-6th', 'education_ 7th-8th', 'education_ 9th', 'education_ Assoc-acdm', 'education_ Assoc-voc', 'education_ Bachelors', 'education_ Doctorate', 'education_ HS-grad', 'education_ Masters', 'education_ Preschool', 'education_ Prof-school', 'education_ Some-college', 'gender_ Female', 'gender_ Male', 'occupation_ ?', 'occupation_ Adm-clerical', 'occupation_ Armed-Forces', 'occupation_ Craft-repair', 'occupation_ Exec-managerial', 'occupation_ Farming-fishing', 'occupation_ Handlers-cleaners', 'occupation_ Machine-op-inspct', 'occupation_ Other-service', 'occupation_ Priv-house-serv', 'occupation_ Prof-specialty', 'occupation_ Protective-serv', 'occupation_ Sales', 'occupation_ Tech-support', 'occupation_ Transport-moving', 'income_ <=50K', 'income_ >50K']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression score on the test set: 0.81\n",
            "X_train.shape is: (284, 80)\n",
            "X_train_selected.shape is: (284, 40)\n",
            "[ True  True  True  True  True  True  True  True  True False  True False\n",
            "  True  True  True  True  True  True False False  True  True  True  True\n",
            "  True  True  True  True  True  True False False False  True False  True\n",
            " False False  True False False False False  True False False  True False\n",
            " False  True False  True False False False False False False  True False\n",
            "  True False False False False  True False  True False False False False\n",
            "  True  True False  True False False False False]\n",
            "The score of Logistic Regression on all features:0.916\n",
            "The score of Logistic Regression on the selected features:0.919\n",
            "The shape of X_train is:  (284, 80)\n",
            "The shape of X_train_s is  (284, 40)\n",
            "The score of Logistic Regression with the selected features on the test set:0.930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}