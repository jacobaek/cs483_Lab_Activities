{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs483_Lab8_Changju.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg5ruITuxct4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "8d233cfc-5610-4b94-c4bc-4647046cbfd0"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "%pwd\n",
        "%cd /content\n",
        "%ls\n",
        "%cd drive/My Drive/Colab Notebooks\n",
        "%ls\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"weather_data.csv\") \n",
        "df\n",
        "\n",
        "df=pd.read_excel(\"weather_data.xlsx\",\"Sheet1\") \n",
        "df\n",
        "\n",
        "\n",
        "weather_data = {\n",
        "    'day': ['1/1/2017','1/2/2017','1/3/2017'],\n",
        "    'temperature': [32,35,28],\n",
        "    'windspeed': [6,7,2],\n",
        "    'event': ['Rain', 'Sunny', 'Snow']\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "df = pd.DataFrame(weather_data) \n",
        "df\n",
        "\n",
        "weather_data = [ ('1/1/2017',32,6,'Rain'),\n",
        "                ('1/2/2017',35,7,'Sunny'),\n",
        "                ('1/3/2017',28,2,'Snow') ]\n",
        "df = pd.DataFrame(data=weather_data,\n",
        "columns=['day','temperature','windspeed','event'])\n",
        "df\n",
        "\n",
        "weather_data = [\n",
        "                {'day': '1/1/2017', 'temperature': 32, 'windspeed': 6, 'event': 'Rain'},\n",
        "                {'day': '1/2/2017', 'temperature': 35, 'windspeed': 7, 'event': 'Sunny'},\n",
        "                {'day': '1/3/2017', 'temperature': 28, 'windspeed': 2, 'event': 'Snow'},\n",
        "                ]\n",
        "df = pd.DataFrame(data=weather_data,\n",
        "columns=['day','temperature','windspeed','event'])\n",
        "df\n",
        "\n",
        "#--------------Read Write Excel CSV File----------------------\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"stock_data.csv\") \n",
        "df\n",
        "\n",
        "df = pd.read_csv(\"stock_data.csv\", skiprows=1) \n",
        "df\n",
        "\n",
        "df = pd.read_csv(\"stock_data.csv\", header=1) # skiprows and header are kind of same\n",
        "df\n",
        "\n",
        "df = pd.read_csv(\"stock_data.csv\", header=None, names =\n",
        "[\"ticker\",\"eps\",\"revenue\",\"people\"])\n",
        "df\n",
        "\n",
        "df = pd.read_csv(\"stock_data.csv\", nrows=2)\n",
        "df\n",
        "\n",
        "df = pd.read_csv(\"stock_data.csv\", na_values=[\"n.a.\", \"not available\"]) \n",
        "df\n",
        "\n",
        "df = pd.read_csv(\"stock_data.csv\", na_values={ 'eps': ['not available'],\n",
        "'revenue': [-1],\n",
        "'people': ['not available','n.a.']\n",
        "})\n",
        "df\n",
        "\n",
        "\n",
        "df.to_csv(\"new.csv\", index=False) \n",
        "df.columns\n",
        "\n",
        "df.to_csv(\"new.csv\",header=False)\n",
        "df.to_csv(\"new.csv\", columns=[\"tickers\",\"price\"], index=False)\n",
        "\n",
        "df = pd.read_excel(\"stock_data.xlsx\",\"Sheet1\") \n",
        "df\n",
        "\n",
        "def convert_people_cell(cell): \n",
        "  if cell==\"n.a.\":\n",
        "    return 'Sam Walton' \n",
        "  return cell\n",
        "\n",
        "def convert_price_cell(cell): \n",
        "  if cell==\"n.a.\":\n",
        "    return 50 \n",
        "  return cell\n",
        "\n",
        "df = pd.read_excel(\"stock_data.xlsx\",\"Sheet1\", converters= { 'people': convert_people_cell,\n",
        "'price': convert_price_cell\n",
        "})\n",
        "df\n",
        "\n",
        "\n",
        "df.to_excel(\"new.xlsx\", sheet_name=\"stocks\", index=False, startrow=2, startcol=1)\n",
        "\n",
        "df_stocks = pd.DataFrame({\n",
        "'tickers': ['GOOGL', 'WMT', 'MSFT'], 'price': [845, 65, 64 ],\n",
        "'pe': [30.37, 14.26, 30.97],\n",
        "'eps': [27.82, 4.61, 2.12]\n",
        "})\n",
        "\n",
        "df_weather = pd.DataFrame({\n",
        "'day': ['1/1/2017','1/2/2017','1/3/2017'],\n",
        "'temperature': [32,35,28], 'event': ['Rain', 'Sunny', 'Snow']\n",
        "})\n",
        "\n",
        "with pd.ExcelWriter('stocks_weather.xlsx') as writer: \n",
        "  df_stocks.to_excel(writer, sheet_name=\"stocks\") \n",
        "  df_weather.to_excel(writer, sheet_name=\"weather\")\n",
        "\n",
        "  #---------------------Handle Missing Data: fillna, dropna, interpolate---------------\n",
        "\n",
        "%cd /content/drive/My Drive/Colab Notebooks\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"weather_data_1.csv\",parse_dates=['day']) \n",
        "type(df.day[0])\n",
        "df\n",
        "\n",
        "df.set_index('day',inplace=True) \n",
        "df\n",
        "\n",
        "new_df = df.fillna(0) \n",
        "new_df\n",
        "\n",
        "new_df = df.fillna({ 'temperature': 0, 'windspeed': 0, 'event': 'No Event' })\n",
        "\n",
        "new_df\n",
        "\n",
        "new_df = df.fillna(method=\"ffill\") \n",
        "new_df\n",
        "\n",
        "new_df = df.fillna(method=\"bfill\") \n",
        "new_df\n",
        "\n",
        "new_df = df.fillna(method=\"bfill\", axis=\"columns\") # axis is either \"index\" or \"columns\"\n",
        "new_df\n",
        "\n",
        "new_df = df.fillna(method=\"ffill\",limit=1) \n",
        "new_df\n",
        "\n",
        "new_df = df.interpolate() \n",
        "new_df\n",
        "\n",
        "new_df = df.interpolate(method=\"time\") \n",
        "new_df\n",
        "\n",
        "new_df = df.dropna() \n",
        "new_df\n",
        "\n",
        "new_df = df.dropna(how='all') \n",
        "new_df\n",
        "\n",
        "new_df = df.dropna(thresh=1)\n",
        "# any row/column with number of Non-NA value < thresh will be removed new_df\n",
        "\n",
        "dt = pd.date_range(\"01-01-2017\",\"01-11-2017\") \n",
        "idx = pd.DatetimeIndex(dt)\n",
        "df.reindex(idx)\n",
        "\n",
        "#-------------------------Handle Missing Data: fillna, dropna, interpolate-------------\n",
        "%cd /content/drive/My Drive/Colab Notebooks\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "df = pd.read_csv(\"weather_data_2.csv\") \n",
        "df\n",
        "\n",
        "new_df = df.replace(-99999, value=np.NaN) \n",
        "new_df\n",
        "\n",
        "new_df = df.replace(to_replace=[-99999,-88888], value=0)\n",
        "new_df\n",
        "\n",
        "new_df = df.replace({\n",
        "'temperature': -99999,\n",
        "'windspeed': -99999,\n",
        "'event': '0'\n",
        "}, np.nan)\n",
        "new_df\n",
        "\n",
        "\n",
        "\n",
        "new_df = df.replace({\n",
        "    -99999: np.nan, 'no event': 'Sunny',\n",
        "\n",
        "\n",
        "})\n",
        "new_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# when windspeed is 6 mph, 7 mph etc. & temperature is 32 F, 28 F etc.\n",
        "new_df = df.replace({'temperature': '[A-Za-z]', 'windspeed': '[a-z]'},'',\n",
        "                    regex=True)\n",
        "new_df\n",
        "\n",
        "df = pd.DataFrame({\n",
        "'score': ['exceptional','average', 'good', 'poor', 'average', 'exceptional'],\n",
        "'student': ['rob', 'maya', 'parthiv', 'tom', 'julian', 'erica']\n",
        "})\n",
        "df\n",
        "\n",
        "df.replace(['poor', 'average', 'good', 'exceptional'], [1,2,3,4])\n",
        "\n",
        "#--------------Group By (Split Apply Combine)------------------\n",
        "%cd /content/drive/My Drive/Colab Notebooks\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"weather_by_cities.csv\") \n",
        "df\n",
        "g = df.groupby(\"city\") \n",
        "g\n",
        "\n",
        "for city, data in g: \n",
        "  print(\"city:\",city) \n",
        "  print(\"\\n\") \n",
        "  print(\"data:\",data)\n",
        "\n",
        "g.get_group('mumbai') \n",
        "g.max()\n",
        "g.mean()\n",
        "\n",
        "g.min() \n",
        "g.describe() \n",
        "g.size()\n",
        "\n",
        "%matplotlib inline \n",
        "g.plot()\n",
        "\n",
        "def grouper(df, idx, col):\n",
        "  if 80 <= df[col].loc[idx] <= 90:\n",
        "    return '80-90'\n",
        "  elif 50 <= df[col].loc[idx] <= 60:\n",
        "    return '50-60' \n",
        "  else:\n",
        "    return 'others'\n",
        "\n",
        "g = df.groupby(lambda x: grouper(df, x, 'temperature')) \n",
        "g\n",
        "\n",
        "for key, d in g:\n",
        "  print(\"Group by Key: {}\\n\".format(key)) \n",
        "  print(d)\n",
        "\n",
        "#----------------Concat Dataframes---------------------\n",
        "import pandas as pd\n",
        "\n",
        "india_weather = pd.DataFrame({\n",
        "\"city\": [\"mumbai\",\"delhi\",\"banglore\"], \"temperature\": [32,45,30],\n",
        "\"humidity\": [80, 60, 78]\n",
        "})\n",
        "india_weather\n",
        "\n",
        "us_weather = pd.DataFrame({ \"city\": [\"new york\",\"chicago\",\"orlando\"], \"temperature\": [21,14,35], \"humidity\": [68, 65, 75] })\n",
        "us_weather\n",
        "\n",
        "df = pd.concat([india_weather, us_weather]) \n",
        "df\n",
        "\n",
        "df = pd.concat([india_weather, us_weather], ignore_index=True)\n",
        "\n",
        "df\n",
        "\n",
        "df = pd.concat([india_weather, us_weather], keys=[\"india\", \"us\"]) \n",
        "df\n",
        "df.loc[\"us\"]\n",
        "\n",
        "df.loc[\"india\"]\n",
        "\n",
        "temperature_df = pd.DataFrame({ \"city\": [\"mumbai\",\"delhi\",\"banglore\"], \"temperature\": [32,45,30],\n",
        "}, index=[0,1,2]) \n",
        "temperature_df\n",
        "\n",
        "windspeed_df = pd.DataFrame({ \"city\": [\"delhi\",\"mumbai\"], \"windspeed\": [7,12],\n",
        "}, index=[1,0]) \n",
        "windspeed_df\n",
        "\n",
        "df = pd.concat([temperature_df,windspeed_df],axis=1) \n",
        "df\n",
        "\n",
        "s = pd.Series([\"Humid\",\"Dry\",\"Rain\"], name=\"event\") \n",
        "s\n",
        "\n",
        "df = pd.concat([temperature_df,s],axis=1) \n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content\n",
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n",
            "/content/drive/My Drive/Colab Notebooks\n",
            " cs483_AI_Lab#1.ipynb               dogs\n",
            " cs483_HW#1_Changju.ipynb           fianl.py\n",
            " cs483_HW#2_Changju.ipynb           newcsv2.csv\n",
            " cs483_HW#3_Changju.ipynb           newcsv3.csv\n",
            " cs483_HW#4_Changju.ipynb           newcsv4.csv\n",
            " cs483_HW#6_Changju.ipynb           smallerfile\n",
            " cs483_Lab#12_Changju_12323.ipynb   Untitled\n",
            " cs483_Lab#2.ipynb                  Untitled0.ipynb\n",
            "'cs483_Lab#3의 사본'               'Untitled (1)'\n",
            " cs483_Lab#3.ipynb                  Untitled1.ipynb\n",
            " cs483_Lab#4.ipynb                  Untitled2.ipynb\n",
            " cs483_Lab#5.ipynb                  Untitled3.ipynb\n",
            " cs483_Lab#6.ipynb                  Untitled4.ipynb\n",
            " cs483_Lab#7_Changju_12323.ipynb    Untitled5.ipynb\n",
            " cs483_Lab7_Changju.ipynb           Untitled6.ipynb\n",
            " cs483_Lab#8_Changju_12323.ipynb    Untitled7.ipynb\n",
            " cs483_Lab8_Changju.ipynb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-956db87210c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weather_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File weather_data.csv does not exist: 'weather_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taqLY9e2ysbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}